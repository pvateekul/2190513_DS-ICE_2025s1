{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98b96f8cf4dc49b58bab0fe6a1762e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0823aede25db4a98ac9c52ba68c984de",
              "IPY_MODEL_efd32d346b2d412e8613278dd95c607b",
              "IPY_MODEL_ea9d9243db8542869bbbba4d0a1beb80"
            ],
            "layout": "IPY_MODEL_32c6017717b645b7a280e407be2cfae5"
          }
        },
        "0823aede25db4a98ac9c52ba68c984de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ac86c01d3f466b92dd14104e725ca6",
            "placeholder": "​",
            "style": "IPY_MODEL_4692b92cb7f8421b90af9c303d916578",
            "value": "100%"
          }
        },
        "efd32d346b2d412e8613278dd95c607b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18878b7c5a784680bc05e3946b5fa665",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0bdccac615b466eab4a5121aa8b4fd8",
            "value": 10
          }
        },
        "ea9d9243db8542869bbbba4d0a1beb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ab69600b364288ba445a028d04707c",
            "placeholder": "​",
            "style": "IPY_MODEL_f9dca54a47ef459ea70a2a26b8060564",
            "value": " 10/10 [00:22&lt;00:00,  2.36s/it]"
          }
        },
        "32c6017717b645b7a280e407be2cfae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ac86c01d3f466b92dd14104e725ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4692b92cb7f8421b90af9c303d916578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18878b7c5a784680bc05e3946b5fa665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0bdccac615b466eab4a5121aa8b4fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53ab69600b364288ba445a028d04707c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9dca54a47ef459ea70a2a26b8060564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overall of this notebook"
      ],
      "metadata": {
        "id": "VXSQW2RpFSYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of concepts and codes are adapted from\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "- https://ai.google.dev/gemini-api/docs/prompting-strategies\n",
        "- https://myframework.net/icio-ai-prompt-framework/"
      ],
      "metadata": {
        "id": "uwrZRFXNFj74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting environments and model setup"
      ],
      "metadata": {
        "id": "tXNDggfzh28Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "id": "ZRhhli6S3UkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Request for Google API KEY here : https://aistudio.google.com/app/apikey"
      ],
      "metadata": {
        "id": "3sT4diEh3gUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "id": "wPsljCqyNPnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525660dc-90a3-4b0b-d317-2daab9f41031"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "sbi2CAPqOHef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic"
      ],
      "metadata": {
        "id": "enmt8H4Shngs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Prompt / User Prompt"
      ],
      "metadata": {
        "id": "rF6TFz-mFEK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`System Prompt`:\n",
        "\n",
        "The system prompt establishes the overall context, persona, and behavioral guidelines for the LLM. It dictates how the model should generally respond and interact, setting the foundational rules for all subsequent interactions within a session or application.\n",
        "\n",
        "`User Prompt (Human)`:\n",
        "\n",
        "  The user prompt is the specific query or instruction provided by the user to the LLM. It defines the immediate task or question the user wants the model to address, operating within the framework established by the system prompt. example\n"
      ],
      "metadata": {
        "id": "6Xuv336sgo_2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYdX-hTxE_vg",
        "outputId": "6ddc9dad-1775-4203-95b8-96fa9401c4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular exercise is fundamental for maintaining physical and mental health, preventing chronic diseases, and enhancing overall well-being and longevity.\n"
          ]
        }
      ],
      "source": [
        "# Demo 1: System - Health Scientist / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are a health scientist who always provides factual and evidence-based answers.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 2: Syetem - Elderly Person Complaining / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are an elderly person who often complains.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y6fndhCsxL9",
        "outputId": "5791c87e-0ec0-4f8e-d3d0-8852fae0e0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, it's just so you don't seize up entirely, I suppose. A real bother, if you ask me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 3: System - Mother Explaining to a 5-year-old / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are a mother who needs to answer questions from a 5-year-old child, always explaining complex topics in the simplest way possible.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2epKy8w5sync",
        "outputId": "a14c05da-b2df-4865-c516-9c078a2cff3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving your body makes you super strong and gives you lots of energy to play all day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 4: Professional Assistant (Python factorial)\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful and informative assistant. Your responses should be clear, concise, and professional. Avoid making assumptions and always ask for clarification if a user's request is ambiguous.\"),\n",
        "    (\"human\", \"Write a Python function that calculates the factorial of a given number.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lblLbxY2s2An",
        "outputId": "699276e4-59cd-4338-a8a8-f1283ae2c083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a given non-negative integer.\n",
            "\n",
            "  Args:\n",
            "    n: An integer for which to calculate the factorial.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n.\n",
            "\n",
            "  Raises:\n",
            "    TypeError: If n is not an integer.\n",
            "    ValueError: If n is a negative integer.\n",
            "  \"\"\"\n",
            "  if not isinstance(n, int):\n",
            "    raise TypeError(\"Input must be an integer.\")\n",
            "  if n < 0:\n",
            "    raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
            "  \n",
            "  if n == 0:\n",
            "    return 1\n",
            "  else:\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "      result *= i\n",
            "    return result\n",
            "\n",
            "# Example Usage:\n",
            "# print(f\"Factorial of 5: {factorial(5)}\")    # Output: Factorial of 5: 120\n",
            "# print(f\"Factorial of 0: {factorial(0)}\")    # Output: Factorial of 0: 1\n",
            "# print(f\"Factorial of 1: {factorial(1)}\")    # Output: Factorial of 1: 1\n",
            "# print(f\"Factorial of 7: {factorial(7)}\")    # Output: Factorial of 7: 5040\n",
            "\n",
            "# Example of error handling:\n",
            "# try:\n",
            "#   print(factorial(-3))\n",
            "# except (TypeError, ValueError) as e:\n",
            "#   print(f\"Error: {e}\") # Output: Error: Factorial is not defined for negative numbers.\n",
            "\n",
            "# try:\n",
            "#   print(factorial(3.5))\n",
            "# except (TypeError, ValueError) as e:\n",
            "#   print(f\"Error: {e}\") # Output: Error: Input must be an integer.\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Prompt Framework - ICIO"
      ],
      "metadata": {
        "id": "8PNPxY_VFH5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ICIO framework is a simple and practical method that **helps you structure your prompts** step by step.\n",
        "- `Instruction (I)` --> What do you want the AI to do?\n",
        "\n",
        "  - The instruction should be specific and direct. A clear task helps the AI give you the right kind of output.\n",
        "- `Context (C)` --> Give background information. Why are you doing this task? What’s the situation?\n",
        "\n",
        "  - Context helps the AI better understand your purpose and tone.\n",
        "  - ***Optional, but nice to have.***\n",
        "\n",
        "- `Input (I)` --> What exact text or data should the AI process?\n",
        "  - Provide the content the AI needs to work with.\n",
        "  - Without input data, the AI may guess or go off track. Be clear and complete.\n",
        "\n",
        "- `Output (O)` --> Set the style or format of the output. What should the response look like? What tone or structure do you expect?\n",
        "  - This helps guide the AI to produce the kind of result you want."
      ],
      "metadata": {
        "id": "fMZNMsDQFL2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Blog Post about AI Ethics\n",
        "\n",
        "# ICIO fields\n",
        "instruction = \"Write a blog post about the ethical issues of AI.\"\n",
        "context = \"The translation is for an internal meeting opening speech.\"\n",
        "input_text = \"Please read this content [url]\"\n",
        "output_format = \"Please use formal business English.\"\n",
        "\n",
        "# Create messages\n",
        "messages = [\n",
        "    (\"system\", \"You are an experienced business writer who creates clear, formal, and professional blog posts.\"),\n",
        "    (\"human\",\n",
        "     f\"{instruction}\\n\"\n",
        "     f\"{context}\\n\"\n",
        "     f\"{input_text}\\n\"\n",
        "     f\"{output_format}\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT3ew0twFKn1",
        "outputId": "1ad6bb96-3cf3-4707-de2c-3b30cc971310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Imperative of Ethical AI: A Foundation for Future Innovation\n",
            "\n",
            "Good morning, everyone.\n",
            "\n",
            "As we gather today, it is with a shared understanding of the profound impact Artificial Intelligence (AI) is having, and will continue to have, on our world, our industry, and our organization. AI is not merely a technological advancement; it is a transformative force reshaping how we work, innovate, and interact. Its potential to drive efficiency, unlock new insights, and create unprecedented value is undeniable and exciting.\n",
            "\n",
            "However, alongside this immense promise comes a critical responsibility. The rapid evolution and deployment of AI technologies necessitate a proactive and rigorous examination of the ethical dimensions inherent in their design, development, and application. Ignoring these considerations would not only be shortsighted but could also undermine the very trust and societal benefit we aim to cultivate.\n",
            "\n",
            "Today, I wish to highlight some of the key ethical challenges we must collectively address as we navigate this new frontier.\n",
            "\n",
            "### Addressing Bias and Ensuring Fairness\n",
            "\n",
            "One of the most significant ethical concerns in AI revolves around bias. AI systems learn from data, and if that data reflects existing societal biases – whether historical, cultural, or systemic – the AI will not only perpetuate but can also amplify these biases. This can lead to discriminatory outcomes in critical areas such as hiring, lending, healthcare, and even justice systems. Our commitment must be to develop AI that is fair, equitable, and does not disadvantage any group. This requires meticulous data curation, algorithmic transparency, and continuous auditing to identify and mitigate bias.\n",
            "\n",
            "### Safeguarding Privacy and Data Security\n",
            "\n",
            "AI thrives on data. The collection, processing, and analysis of vast datasets raise fundamental questions about individual privacy and data security. How do we ensure that personal information is protected, used only for its intended purpose, and not vulnerable to misuse or breaches? Establishing robust data governance frameworks, ensuring informed consent, and implementing state-of-the-art security measures are paramount to maintaining public trust and adhering to regulatory standards.\n",
            "\n",
            "### Ensuring Accountability and Transparency\n",
            "\n",
            "The complexity of advanced AI models, often referred to as \"black boxes,\" can make it challenging to understand how they arrive at specific decisions or predictions. This lack of transparency poses a significant ethical dilemma: who is accountable when an AI system makes an error or causes harm? We must strive for greater explainability in AI, enabling us to understand the rationale behind its outputs. Establishing clear lines of responsibility and developing mechanisms for human oversight are crucial for fostering trust and ensuring ethical governance.\n",
            "\n",
            "### Navigating Societal Impact and Job Displacement\n",
            "\n",
            "The increasing automation powered by AI will inevitably reshape the workforce. While AI can augment human capabilities and create new roles, it also carries the potential for job displacement in certain sectors. As responsible innovators, we must consider the broader societal implications of our AI deployments. This includes investing in reskilling and upskilling initiatives, fostering a culture of continuous learning, and contributing to solutions that ensure a just transition for affected individuals and communities.\n",
            "\n",
            "### Combating Misinformation and Manipulation\n",
            "\n",
            "The generative capabilities of AI, while powerful for creativity and content generation, also present a risk of creating convincing misinformation, deepfakes, and propaganda. The potential for AI to be used for malicious purposes, to manipulate public opinion, or to erode trust in information sources is a serious ethical challenge. We must develop and advocate for safeguards, detection mechanisms, and ethical guidelines to prevent the misuse of AI in this domain.\n",
            "\n",
            "### Our Collective Responsibility\n",
            "\n",
            "These ethical considerations are not merely abstract philosophical debates; they are practical challenges that demand our immediate and sustained attention. Addressing them is not just about compliance; it is about building a sustainable future for our organization and for society at large. It is about ensuring that AI serves humanity's best interests, enhances our capabilities, and contributes positively to our collective well-being.\n",
            "\n",
            "As we move forward, let us commit to embedding ethical principles into every stage of our AI lifecycle – from conception and design to deployment and ongoing monitoring. Let us foster open dialogue, encourage critical thinking, and collaborate across disciplines to develop AI solutions that are not only innovative and powerful but also fair, transparent, and accountable.\n",
            "\n",
            "Thank you. Let us now begin our discussion on how we can collectively champion ethical AI within our organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2A: Customer Feedback Summary\n",
        "\n",
        "# ICIO fields\n",
        "instruction = \"Summarize customer opinions.\"\n",
        "context = \"For the product development team to consider improvements in the next version.\"\n",
        "input_text = (\n",
        "    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n",
        "    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n",
        "    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n",
        "    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n",
        "    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",
        ")\n",
        "output_format = 'Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".'\n",
        "\n",
        "# Create messages\n",
        "messages = [\n",
        "    (\"system\", \"You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\"),\n",
        "    (\"human\",\n",
        "     f\"{instruction}\\n\"\n",
        "     f\"{context}\\n\"\n",
        "     f\"{input_text}\\n\"\n",
        "     f\"{output_format}\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdJiPsAhm1F7",
        "outputId": "f68e2bab-1197-4ae0-860a-c2df8cbd730e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of customer opinions for the product development team:\n",
            "\n",
            "| Feature                     | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n",
            "| :-------------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n",
            "| **Battery Life**            | Good                                      | Lasts up to 3 days, a significant improvement over the older version. |\n",
            "| **AMOLED Screen / Display** | Good                                      | Provides vibrant colors and is clearly visible under bright sunlight. |\n",
            "| **Bluetooth Connectivity**  | Needs Improvement                         | Connections with certain headphones often drop.                    |\n",
            "| **Sleep Tracking System**   | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n",
            "| **Blood Pressure Monitoring** | Requested                                 | Customers would like to see this function added.                   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***To summarize, recognizing ICIO when prompting helps ensure the prompt is complete and clear, and that the LLM provides the desired output.***"
      ],
      "metadata": {
        "id": "m7g0kOfg4xdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine"
      ],
      "metadata": {
        "id": "9hTlvQdLAWUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "  - In practice, many modern prompts don't separate system and user instructions. Instead, they combine them into a single, comprehensive prompt.\n",
        "  - This approach is effective because today's large language models are skilled at understanding and following complex, structured instructions.\n",
        "  - You can define the model's persona, give it specific instructions, and provide the necessary data all within one prompt."
      ],
      "metadata": {
        "id": "VnE7OTnc_uWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2B: Customer Feedback Summary (Single Prompt)\n",
        "\n",
        "prompt = '''\n",
        "You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\n",
        "Summarize customer opinions for the product development team to consider improvements in the next version.\n",
        "Customer Opinions:\n",
        "    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n",
        "    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n",
        "    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n",
        "    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n",
        "    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",
        "Output: Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".\n",
        "'''\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AkndWCsAOdn",
        "outputId": "8d7b5301-a340-443f-df4f-f929444c5ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of customer opinions for the product development team:\n",
            "\n",
            "| Feature                     | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n",
            "| :-------------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n",
            "| **Battery Life**            | Good                                      | Lasts up to 3 days, a significant improvement over the older version. |\n",
            "| **AMOLED Screen**           | Good                                      | Provides vibrant colors and is clearly visible under bright sunlight. |\n",
            "| **Bluetooth Connectivity**  | Needs Improvement                         | Users report frequent connection drops with certain headphones.    |\n",
            "| **Sleep Tracking**          | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n",
            "| **Blood Pressure Monitoring** | Requested                                 | Customers would like to see this function added.                   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Input"
      ],
      "metadata": {
        "id": "mKdBOwfBnlDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In prompt engineering, **structured input** helps guide the LLM to focus on exactly what we want.  \n",
        "\n",
        "One common technique is using **delimiters** (special symbols or markers) to clearly separate instructions, context, and input data.\n",
        "\n",
        "\n",
        "Why use delimiters?\n",
        "- They **reduce ambiguity** → the model doesn’t “guess” where instructions or content begin/end.  \n",
        "- They **minimize misinterpretation** → the model treats the content inside delimiters as a defined block.  \n",
        "- They are especially useful when prompts are **long, multi-part, or contain different types of information**.\n",
        "---\n",
        "\n",
        "Examples of delimiters\n",
        "\n",
        "You can use different symbols such as:\n",
        "- Triple dashes (---)\n",
        "- Triple hashtags (###)\n",
        "- Triple backticks: \\`\\`\\` ... \\`\\`\\`\n",
        "- Triple quotes: \"\"\" ... \"\"\"\n",
        "- Angle brackets: < ... >\n",
        "- Tags: `<instruction> ... </instruction>`"
      ],
      "metadata": {
        "id": "H3oDxvd0p0Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The raw text to be summarized\n",
        "text = \"\"\"\n",
        "In the digital age, online marketing has become the cornerstone of businesses of all sizes, offering a broad reach to consumers at a lower cost than traditional marketing.\n",
        "Popular online marketing tools include SEO (Search Engine Optimization), Social Media Marketing, and high-quality Content Marketing.\n",
        "Leveraging data analytics also helps businesses analyze customer behavior and refine their strategies effectively.\n",
        "\"\"\"\n",
        "\n",
        "# The prompt using delimiters (triple backticks ```)\n",
        "prompt = f\"\"\"You are a helpful assistant.\n",
        "Summarize the text within the triple backticks concisely, in no more than two sentences.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0We1kF19Tea",
        "outputId": "66074055-82ef-4317-ec9a-f2b4612a73eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Online marketing is essential for businesses today, offering broad consumer reach at a lower cost than traditional methods. Key tools include SEO, social media, and content marketing, with data analytics further refining strategies based on customer behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "<Instructions>\n",
        "You are a marketing expert. Analyze the article within <Article> and provide recommendations based on the topics outlined in <Response_Format>.\n",
        "</Instructions>\n",
        "\n",
        "<Article>\n",
        "Our company recently launched a new smartwatch, but sales have been disappointing. Most customers say the features aren't unique compared to competitors, and the price is too high for the value they receive.\n",
        "</Article>\n",
        "\n",
        "<Response_Format>\n",
        "### Problem Analysis:\n",
        "- [Summary of main issues]\n",
        "\n",
        "### Strategic Recommendations:\n",
        "- [Suggestion for the product]\n",
        "- [Suggestion for pricing]\n",
        "- [Suggestion for marketing communications]\n",
        "</Response_Format>\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlZpQYyQ97Zu",
        "outputId": "2b13d1a1-3035-4e33-e683-2244caa232b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Problem Analysis:\n",
            "- **Lack of Product Differentiation:** The core issue is that customers perceive the smartwatch's features as not unique when compared to competitors, leading to a lack of compelling reasons to choose this product.\n",
            "- **Poor Price-Value Perception:** Customers feel the current price is too high relative to the value they receive, indicating a mismatch between the product's perceived worth and its cost.\n",
            "- **Disappointing Sales:** These underlying issues are directly contributing to the poor sales performance of the newly launched smartwatch.\n",
            "\n",
            "### Strategic Recommendations:\n",
            "\n",
            "- **Suggestion for the product:**\n",
            "    *   **Identify and Enhance Unique Selling Propositions (USPs):** Conduct a thorough competitive analysis to pinpoint areas where the product *could* differentiate itself. This might involve software updates to introduce novel features (e.g., specialized health tracking, unique app integrations, longer battery life, specific design elements) or focusing on a niche market where existing features might be more valued. If true uniqueness is difficult, focus on superior execution or a combination of features that, while not individually unique, create a compelling overall package.\n",
            "    *   **Gather Deeper Customer Insights:** Beyond general feedback, conduct surveys, focus groups, or user testing to understand what features customers *truly* desire and what pain points are currently unmet by competitors. This can inform future product development or highlight overlooked strengths.\n",
            "\n",
            "- **Suggestion for pricing:**\n",
            "    *   **Re-evaluate Pricing Strategy:** Consider a tiered pricing model (e.g., a \"standard\" version at a lower, more competitive price point and a \"premium\" version with additional features or services). Alternatively, conduct a value-based pricing analysis to determine what customers are *willing* to pay for the current feature set, potentially leading to a price reduction to align with perceived value.\n",
            "    *   **Bundle and Promote:** Offer introductory promotions, bundles with complementary products (e.g., extra straps, extended warranty, premium app subscriptions), or trade-in programs to increase the perceived value without necessarily lowering the base price.\n",
            "\n",
            "- **Suggestion for marketing communications:**\n",
            "    *   **Shift Focus to Benefits and Solutions:** Instead of just listing features, communicate how the smartwatch's features solve specific customer problems or enhance their daily lives. Even if features aren't unique, highlight the *superior experience* or *specific benefits* they offer (e.g., \"seamless integration with X,\" \"reliable health insights for Y,\" \"designed for Z lifestyle\").\n",
            "    *   **Emphasize Value Proposition:** Clearly articulate *why* the product is worth its price. This involves showcasing any subtle differentiators, superior build quality, excellent customer support, or long-term value (e.g., durability, future-proof technology). Use testimonials, case studies, and influencer marketing to build credibility and demonstrate real-world value.\n",
            "    *   **Target Specific Segments:** If the product has particular strengths that appeal to a niche, tailor marketing messages to those specific segments. For example, if it's great for fitness enthusiasts, focus on that; if it's ideal for busy professionals, highlight productivity features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "- `<Instructions>`: Sets the model's persona and primary objective.\n",
        "\n",
        "- `<Article>`: Contains the raw data to be analyzed.\n",
        "\n",
        "- `<Response_Format>`: Clearly outlines the desired structure of the output. This forces the model to organize its response systematically and address all specified points.\n",
        "\n"
      ],
      "metadata": {
        "id": "BzHT8XuQ-5En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Output"
      ],
      "metadata": {
        "id": "1-MIkua_qMkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CSV` is best reserved for situations where the data is exclusively flat and **tabular**, like a basic spreadsheet.\n",
        "\n",
        "`JSON` is the clear winner for most tasks today because it can handle **hierarchical and nested data**. This is essential for working with APIs, configurations, and any data that isn't a simple table. It also natively supports data types like integers, strings, and booleans, which simplifies processing."
      ],
      "metadata": {
        "id": "HJ40UxIZqQe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : CSV"
      ],
      "metadata": {
        "id": "eI45ATexGx3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Structured output (CSV)\n",
        "prompt = \"\"\"You are a helpful assistant.\n",
        "**Task:** Convert the following customer list into a CSV string.\n",
        "**Output Format:** The first row should contain the headers \"Name\" and \"City\". The subsequent rows should contain the customer data, with values separated by commas.\n",
        "**Data:**\n",
        "- John Doe from New York\n",
        "- Jane Smith from London\n",
        "- Peter Jones from Tokyo\n",
        "\"\"\"\n",
        "\n",
        "ai_msg_csv = llm.invoke(prompt)\n",
        "print(\"Structured Output:\\n\", ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1N_Awr4qPtT",
        "outputId": "38aa495f-c4da-4fea-92a7-460b8d9d3418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured Output:\n",
            " ```csv\n",
            "Name,City\n",
            "John Doe,New York\n",
            "Jane Smith,London\n",
            "Peter Jones,Tokyo\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parsing CSV Output into a DataFrame"
      ],
      "metadata": {
        "id": "snb2aS38F04e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."
      ],
      "metadata": {
        "id": "Tpz49DBWF6Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def csv_string_to_df(text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts CSV content from a string and converts it into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing CSV content enclosed in ```csv...```.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame containing the extracted data.\n",
        "    \"\"\"\n",
        "    # Use a regex pattern to find the content between the delimiters\n",
        "    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract the content from the first capturing group\n",
        "        csv_content = match.group(1).strip()\n",
        "\n",
        "        # Use io.StringIO to treat the string as a file\n",
        "        data = io.StringIO(csv_content)\n",
        "\n",
        "        # Read the \"file\" into a pandas DataFrame\n",
        "        df = pd.read_csv(data)\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        # Return an empty DataFrame or raise an error if no match is found\n",
        "        print(\"No CSV content found within ```csv...``` delimiters.\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "9F0mecNaEi3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_string_to_df(ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rmEcEtk7GE8q",
        "outputId": "ba48c4f6-6112-4210-8271-b647a546b0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Name      City\n",
              "0     John Doe  New York\n",
              "1   Jane Smith    London\n",
              "2  Peter Jones     Tokyo"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71931238-c85f-432a-8b02-083d94ce8174\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jane Smith</td>\n",
              "      <td>London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Peter Jones</td>\n",
              "      <td>Tokyo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71931238-c85f-432a-8b02-083d94ce8174')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71931238-c85f-432a-8b02-083d94ce8174 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71931238-c85f-432a-8b02-083d94ce8174');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0d0cc34-9cf7-4600-b3c1-9da6232618ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0d0cc34-9cf7-4600-b3c1-9da6232618ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0d0cc34-9cf7-4600-b3c1-9da6232618ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"csv_string_to_df(ai_msg_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : JSON"
      ],
      "metadata": {
        "id": "qUqbr39-G8kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Structured output (JSON)\n",
        "prompt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "For the given student record, return a JSON object with the following fields:\n",
        "- name (string) → student’s full name\n",
        "- age (integer) → student’s age\n",
        "- scores (object) → nested dictionary with subject name as key and integer score as value\n",
        "- extracurricular (array of strings) → list of activities\n",
        "\n",
        "Student Record:\n",
        "Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "ai_msg_json = llm.invoke(prompt)\n",
        "print(\"Structured Output:\\n\", ai_msg_json.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00867d16-8cea-4705-8988-6b83275bca32",
        "id": "PkbM0hvuG8kl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured Output:\n",
            " ```json\n",
            "{\n",
            "  \"name\": \"Alice\",\n",
            "  \"age\": 21,\n",
            "  \"scores\": {\n",
            "    \"Math\": 85,\n",
            "    \"English\": 92\n",
            "  },\n",
            "  \"extracurricular\": [\n",
            "    \"Basketball\",\n",
            "    \"Drama Club\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def json_string_to_dict(text: str):\n",
        "    \"\"\"\n",
        "    Extracts JSON content from a string enclosed in ```json...```\n",
        "    and parses it into a Python dict or list.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing JSON content enclosed in ```json...```.\n",
        "\n",
        "    Returns:\n",
        "        dict or list: Parsed JSON object (Python dict or list).\n",
        "    \"\"\"\n",
        "    # Use regex to find JSON block\n",
        "    match = re.search(r'```json\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract JSON content\n",
        "        json_content = match.group(1).strip()\n",
        "\n",
        "        try:\n",
        "            return json.loads(json_content)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"Invalid JSON:\", e)\n",
        "            return None\n",
        "    else:\n",
        "        print(\"No JSON content found within ```json...``` delimiters.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "mVl5noz0M8AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_output = json_string_to_dict(ai_msg_json.content)\n",
        "dict_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUIY-djMM-P_",
        "outputId": "8e1ecf23-1fc3-42de-d669-fce1481309a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Alice',\n",
              " 'age': 21,\n",
              " 'scores': {'Math': 85, 'English': 92},\n",
              " 'extracurricular': ['Basketball', 'Drama Club']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_output['scores']['Math']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KjqbbnvNeE4",
        "outputId": "9916bb03-36fa-47dd-b880-d6b3f51937df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parsing JSON Output into Dict"
      ],
      "metadata": {
        "id": "e6UZdGS6G8kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."
      ],
      "metadata": {
        "id": "pbYRVsTRG8kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def csv_string_to_df(text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts CSV content from a string and converts it into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing CSV content enclosed in ```csv...```.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame containing the extracted data.\n",
        "    \"\"\"\n",
        "    # Use a regex pattern to find the content between the delimiters\n",
        "    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract the content from the first capturing group\n",
        "        csv_content = match.group(1).strip()\n",
        "\n",
        "        # Use io.StringIO to treat the string as a file\n",
        "        data = io.StringIO(csv_content)\n",
        "\n",
        "        # Read the \"file\" into a pandas DataFrame\n",
        "        df = pd.read_csv(data)\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        # Return an empty DataFrame or raise an error if no match is found\n",
        "        print(\"No CSV content found within ```csv...``` delimiters.\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "-MF5J3BrG8kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_string_to_df(ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d0b79623-0e0a-4fe3-fa10-3d30986da7a4",
        "id": "WRw4hnlHG8kl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Name      City\n",
              "0     John Doe  New York\n",
              "1   Jane Smith    London\n",
              "2  Peter Jones     Tokyo"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2bb43db-5a47-49a2-ab69-beadb8889ac6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jane Smith</td>\n",
              "      <td>London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Peter Jones</td>\n",
              "      <td>Tokyo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2bb43db-5a47-49a2-ab69-beadb8889ac6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2bb43db-5a47-49a2-ab69-beadb8889ac6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2bb43db-5a47-49a2-ab69-beadb8889ac6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2d1fd05e-bf14-4e40-85aa-28c03f96ba85\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d1fd05e-bf14-4e40-85aa-28c03f96ba85')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2d1fd05e-bf14-4e40-85aa-28c03f96ba85 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"csv_string_to_df(ai_msg_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : Pydantic Schema"
      ],
      "metadata": {
        "id": "QR96B7zq0pfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LangChain supports structured outputs, **allowing us to bind a schema (dict / JSON Schema / Pydantic) to the model**\n",
        "  - and enforce responses to follow the defined structure instead of relying only on prompt wording.\n",
        "- ***However, complex output structures may still fail, so prompting and custom parsing function are still important in some cases.***\n",
        "\n",
        "Read more: [LangChain Docs – Structured Outputs](https://python.langchain.com/docs/concepts/structured_outputs/)\n"
      ],
      "metadata": {
        "id": "V9xRrjgy09pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pydantic schema\n",
        "\n",
        "# suppose that we want the output something like this :\n",
        "'''{'name': 'Alice',\n",
        " 'age': 21,\n",
        " 'scores': {'Math': 85, 'English': 92},\n",
        " 'extracurricular': ['Basketball', 'Drama Club']}'''\n",
        "\n",
        "# we can defined class (data fields) like this\n",
        "\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class DesiredOutput(BaseModel):\n",
        "    name: str = Field(description=\"Student's first name\")\n",
        "    age: int = Field(description=\"Age in years\")\n",
        "    extracurricular: List[str] = Field(description=\"List of activities/clubs\")\n",
        "\n",
        "    #subject_scores: Dict[str, int] = Field(description=\"Key = subject, Value = scores (as a JSON object)\")\n",
        "\n",
        "    # This line cause an error. / Complex Data Structure (uncomment if you want to test it)"
      ],
      "metadata": {
        "id": "DLSKUOVy0uN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap LLM so it returns a DesiredOutput object directly\n",
        "structured_llm = llm.with_structured_output(DesiredOutput)"
      ],
      "metadata": {
        "id": "LNMNByvN27fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "For the given student record, extract informations\n",
        "\n",
        "Student Record:\n",
        "Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Generate output\n",
        "results = structured_llm.invoke(prompt)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJc0JMrS3pld",
        "outputId": "fdd9b3e9-7acb-4db6-e8f8-3697a3d179d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DesiredOutput(name='Alice', age=21, extracurricular=['Basketball', 'Drama Club'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.model_dump_json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fqArflod__Q4",
        "outputId": "2fc23255-a2b9-4af6-ffed-2085e39b887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"name\":\"Alice\",\"age\":21,\"extracurricular\":[\"Basketball\",\"Drama Club\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Condition\n",
        "- **Don't know, don't guess**  \n",
        "  Instruct the model to answer *\"I don’t know\"* if the information is unknown or unverifiable.  \n",
        "  → Helps prevent the model from attempting to answer overly difficult or specific open-ended questions.  \n",
        "  > Note: This depends on the **use case** — but in scenarios where we *don’t want the model to attempt an uncertain answer*, this condition is very useful.\n",
        "\n",
        "- **Output Format Remarking**  \n",
        "  Explicitly remind the model about the required output format.  \n",
        "  → e.g., *\"Don’t give any additional explanation, just output [format] only.\"*"
      ],
      "metadata": {
        "id": "3xeHCngFhtAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Without boundary condition\n",
        "prompt = \"\"\"\n",
        "What are the details of the announcement from the Meteorological Department, ฉบับที่ 2/2568 เรื่อง 'มาตรการรับมือพายุฤดูร้อนก่อนกำหนด'?\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(\"With boundary condition:\\n\", ai_msg.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVMrB0dcd1ic",
        "outputId": "affed9ad-1451-4362-b77a-903b2a28fb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With boundary condition:\n",
            " ประกาศกรมอุตุนิยมวิทยา ฉบับที่ 2/2568 ที่คุณอ้างถึงในชื่อ \"มาตรการรับมือพายุฤดูร้อนก่อนกำหนด\" นั้น **ไม่ใช่ชื่อประกาศอย่างเป็นทางการ** ครับ\n",
            "\n",
            "ประกาศกรมอุตุนิยมวิทยา ฉบับที่ 2/2568 ที่ออกเมื่อวันที่ 21 กุมภาพันธ์ 2568 (ค.ศ. 2025) มีชื่อเรื่องอย่างเป็นทางการว่า **\"เรื่อง การเข้าสู่ฤดูร้อนของประเทศไทย พ.ศ. 2568\"** (Announcement of the Meteorological Department Regarding the Entry into Summer in Thailand B.E. 2568)\n",
            "\n",
            "แม้ว่าประกาศฉบับนี้จะไม่ได้เน้นที่ \"มาตรการรับมือ\" โดยตรง แต่ได้ให้ข้อมูลสำคัญเกี่ยวกับการคาดการณ์สภาพอากาศในฤดูร้อน ซึ่งรวมถึงการเกิดพายุฤดูร้อนด้วยครับ\n",
            "\n",
            "**รายละเอียดสำคัญของประกาศฉบับที่ 2/2568 \"เรื่อง การเข้าสู่ฤดูร้อนของประเทศไทย พ.ศ. 2568\" มีดังนี้:**\n",
            "\n",
            "1.  **การเข้าสู่ฤดูร้อน:**\n",
            "    *   ประเทศไทยได้สิ้นสุดฤดูหนาวและเข้าสู่ฤดูร้อนอย่างเป็นทางการแล้ว **ตั้งแต่วันที่ 21 กุมภาพันธ์ พ.ศ. 2568**\n",
            "    *   การเข้าสู่ฤดูร้อนในปีนี้ถือว่า **เร็วกว่าค่าเฉลี่ยปกติ** เล็กน้อย (ปกติจะเข้าสู่ฤดูร้อนประมาณปลายเดือนกุมภาพันธ์ถึงต้นเดือนมีนาคม)\n",
            "\n",
            "2.  **เกณฑ์การพิจารณา:**\n",
            "    *   ลมที่พัดปกคลุมประเทศไทยตอนบนได้เปลี่ยนทิศทางจากลมตะวันออกเฉียงเหนือเป็น **ลมใต้และลมตะวันออกเฉียงใต้** พัดปกคลุม\n",
            "    *   อุณหภูมิสูงขึ้นอย่างต่อเนื่องและมีอากาศร้อนในหลายพื้นที่ โดยมีอุณหภูมิสูงสุดตั้งแต่ 35 องศาเซลเซียสขึ้นไป\n",
            "    *   ปริมาณฝนลดลงและอากาศหนาวเย็นลดลง\n",
            "\n",
            "3.  **การคาดการณ์สภาพอากาศในฤดูร้อน 2568:**\n",
            "    *   **อากาศร้อนถึงร้อนจัด:** โดยทั่วไปจะมีอากาศร้อนถึงร้อนจัดในหลายพื้นที่ โดยเฉพาะช่วงกลางวัน\n",
            "    *   **อุณหภูมิสูงสุด:** คาดว่าอุณหภูมิสูงสุดจะสูงถึง 43-44 องศาเซลเซียสในบางพื้นที่\n",
            "    *   **พายุฤดูร้อน:** ในช่วงฤดูร้อนนี้ **จะเกิดพายุฤดูร้อนขึ้นในหลายพื้นที่** โดยเฉพาะในช่วงกลางเดือนมีนาคมถึงกลางเดือนพฤษภาคม\n",
            "        *   ลักษณะของพายุฤดูร้อนจะประกอบด้วย **พายุฝนฟ้าคะนอง ลมกระโชกแรง ลูกเห็บตก และฟ้าผ่า**\n",
            "        *   กรมอุตุนิยมวิทยาจะออกประกาศเตือนเป็นระยะเมื่อมีแนวโน้มการเกิดพายุฤดูร้อน\n",
            "\n",
            "4.  **การสิ้นสุดฤดูร้อน:**\n",
            "    *   คาดว่าฤดูร้อนของประเทศไทยจะสิ้นสุดลงประมาณกลางเดือนพฤษภาคม 2568\n",
            "\n",
            "**สรุปเกี่ยวกับ \"มาตรการรับมือพายุฤดูร้อนก่อนกำหนด\":**\n",
            "\n",
            "แม้ว่าประกาศฉบับที่ 2/2568 จะไม่ได้ระบุ \"มาตรการรับมือ\" โดยละเอียด แต่ได้ **เตือนให้ประชาชนเตรียมพร้อมรับมือกับพายุฤดูร้อน** ที่จะเกิดขึ้นในช่วงฤดูร้อนนี้ โดยเฉพาะช่วงกลางเดือนมีนาคมถึงกลางเดือนพฤษภาคม ซึ่งถือเป็นการแจ้งเตือนล่วงหน้าเพื่อให้ประชาชนและหน่วยงานที่เกี่ยวข้องได้เตรียมการ\n",
            "\n",
            "**คำแนะนำทั่วไปในการรับมือพายุฤดูร้อน (ซึ่งมักจะมาจากกรมอุตุนิยมวิทยาและกรมป้องกันและบรรเทาสาธารณภัย):**\n",
            "\n",
            "*   **ติดตามข่าวสาร:** ติดตามประกาศจากกรมอุตุนิยมวิทยาอย่างใกล้ชิด\n",
            "*   **ตรวจสอบความแข็งแรง:** ตรวจสอบความแข็งแรงของอาคารบ้านเรือน ป้ายโฆษณา และสิ่งปลูกสร้างต่างๆ\n",
            "*   **หลีกเลี่ยงที่โล่งแจ้ง:** งดการอยู่ในที่โล่งแจ้ง ใต้ต้นไม้ใหญ่ หรือป้ายโฆษณาที่ไม่แข็งแรงขณะเกิดพายุ\n",
            "*   **ระมัดระวังอันตราย:** ระมัดระวังอันตรายจากฟ้าผ่า\n",
            "*   **เก็บสิ่งของ:** เก็บสิ่งของที่ปลิวลมได้ง่ายเข้าที่\n",
            "*   **เตรียมพร้อม:** เตรียมอุปกรณ์ฉุกเฉิน เช่น ไฟฉาย วิทยุถ่าน และน้ำดื่ม\n",
            "\n",
            "ดังนั้น ประกาศฉบับที่ 2/2568 เป็นการแจ้งเตือนการเข้าสู่ฤดูร้อนและการคาดการณ์สภาพอากาศโดยรวม รวมถึงการเตือนถึงพายุฤดูร้อนที่จะเกิดขึ้น ซึ่งเป็นข้อมูลพื้นฐานสำคัญสำหรับการเตรียมพร้อมรับมือครับ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: With boundary condition\n",
        "prompt = \"\"\"\n",
        "What are the details of the announcement from the Meteorological Department, ฉบับที่ 2/2568 เรื่อง 'มาตรการรับมือพายุฤดูร้อนก่อนกำหนด'?\n",
        "\n",
        "If the answer is not known or cannot be verified, just reply: `I don’t know`.\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(\"With boundary condition:\\n\", ai_msg.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFYUTpPeyR4v",
        "outputId": "4228a389-6c9e-47d7-c8fa-29ecc1a154f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With boundary condition:\n",
            " I don’t know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template\n",
        "\n",
        "Prompt templates offer several benefits:\n",
        "\n",
        "- **Consistency**: Ensure a consistent structure for your prompts across multiple interactions\n",
        "- **Efficiency**: Easily swap out variable content without rewriting the entire prompt\n",
        "- **Testability**: Quickly test different inputs and edge cases by changing only the variable portion\n",
        "- **Scalability***: Simplify prompt management as your application grows in complexity\n",
        "- **Version control**: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs"
      ],
      "metadata": {
        "id": "UyIZT0fiz-x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: Prompt Template in a Loop (Task: Sentiment Analysis)\n",
        "\n",
        "Example Task: **Sentiment Analysis**\n",
        "\n",
        "We used a prompt template with the approach **“run in a loop + change only variables”**.  \n",
        "This demonstrates how prompt templates cover several benefits at once:\n",
        "\n",
        "- **Consistency**: Every iteration uses the same prompt structure.  \n",
        "- **Efficiency**: Only the variable `{text}` changes in each loop.  \n",
        "- **Testability**: Multiple inputs can be tested quickly by swapping variable values.  \n",
        "- **Scalability**: The same template can be applied to a larger dataset without modification.  \n",
        "- **Version Control**: Easily track prompt versions against results.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3R-tfOsrRG7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"
      ],
      "metadata": {
        "id": "4ryOL6guq0C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857fb340-7486-42d8-b7f0-5fb744c00604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-07 18:04:51--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n",
            "--2025-11-07 18:04:51--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122071 (119K) [text/plain]\n",
            "Saving to: ‘dev.txt’\n",
            "\n",
            "dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-11-07 18:04:52 (75.4 MB/s) - ‘dev.txt’ saved [122071/122071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split(' ||| ')\n",
        "            x_data.append(text)\n",
        "            y_data.append(int(label))\n",
        "    return x_data, y_data"
      ],
      "metadata": {
        "id": "fXa_FpBL6zt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = read_xy_data('dev.txt')\n",
        "x_test, y_test = x_test[:10], y_test[:10] # small size for quick testing"
      ],
      "metadata": {
        "id": "IbNrlgaWRVz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For sentiment analysis, we will be using the following prompt:\n",
        "\n",
        "```\n",
        "Analyse the sentiment of the following text: ```text```\n",
        "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
        "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
        "```\n",
        "LLMs nowaday usually have chain-of-thought baked in so they usually will output their reasoning before answering.\n",
        "\n",
        "- It is important to tell the model not to output their explanation by including `**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
        "`\n",
        "- Otherwise, it will not be easy to programmatically use the outputs.\n",
        "Alternatively, you can use structured outputs `(see table of contents -> Structured Output)` for ease of parsing."
      ],
      "metadata": {
        "id": "6EU6prW_oeTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Analyse the sentiment of the following text: ```{x_input}```\n",
        "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
        "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\"\"\""
      ],
      "metadata": {
        "id": "y3wwc3vJiiJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "Py85PRxuXwjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for sent in tqdm(x_test):\n",
        "   try:\n",
        "      prompt_filled = prompt_template.format(x_input=sent)\n",
        "      print('prompt:', prompt_filled) # debugging\n",
        "      output_res = llm.invoke(prompt_filled).content.strip()\n",
        "      print('response:', output_res) # debugging\n",
        "      print('--'*20)\n",
        "      output.append(int(output_res))\n",
        "   except:\n",
        "      output.append(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "98b96f8cf4dc49b58bab0fe6a1762e44",
            "0823aede25db4a98ac9c52ba68c984de",
            "efd32d346b2d412e8613278dd95c607b",
            "ea9d9243db8542869bbbba4d0a1beb80",
            "32c6017717b645b7a280e407be2cfae5",
            "96ac86c01d3f466b92dd14104e725ca6",
            "4692b92cb7f8421b90af9c303d916578",
            "18878b7c5a784680bc05e3946b5fa665",
            "c0bdccac615b466eab4a5121aa8b4fd8",
            "53ab69600b364288ba445a028d04707c",
            "f9dca54a47ef459ea70a2a26b8060564"
          ]
        },
        "id": "QFFPVtwT9rjZ",
        "outputId": "80e01c92-d0bc-4e13-b198-9242e941dec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98b96f8cf4dc49b58bab0fe6a1762e44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: \n",
            "Analyse the sentiment of the following text: ```It 's a lovely film with lovely performances by Buy and Accorsi .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```No one goes unindicted here , which is probably for the best .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```A warm , funny , engaging film .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Half Submarine flick , Half Ghost Story , All in one criminally neglected film```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Entertains by providing good , lively company .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Dazzles with its fully-written characters , its determined stylishness -LRB- which always relates to characters and story -RRB- and Johnny Dankworth 's best soundtrack in years .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Nothing 's at stake , just a twisty double-cross you can smell a mile away -- still , the derivative Nine Queens is lots of fun .```\n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp7ZS8hKVRb8",
        "outputId": "ee999d68-edf7-47a7-a41c-05bfdfec9d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional: Temperature Setting"
      ],
      "metadata": {
        "id": "_AryYrz0F-Pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Settings to keep in mind\n",
        "\n",
        "- Temperature is an important parameter to consider.\n",
        "  - Keep it low if you are looking for exact or deterministic answers.\n",
        "  - Keep it high if you are looking for more diverse or creative responses.\n",
        "\n",
        "> In all the previous examples, we only set up the LLM once, and the parameter was fixed as Temperature = 0\n",
        "\n",
        "This means every example so far was generated with a deterministic setting (no randomness)."
      ],
      "metadata": {
        "id": "oNWq0plMFcEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature Range for Gemini-2.5-flash : 0-2 (default 1)\n",
        "\n",
        ">Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash"
      ],
      "metadata": {
        "id": "mJA6w0hAdyxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_low_temp = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "1LscvX8fjVzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_high_temp = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=2,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "gx4NPLujeWZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_low_temp\n",
        "prompt = \"Write one slogan for a mobile banking application.\"\n",
        "for rnd in range(3):\n",
        "  try:\n",
        "    output_res = llm_low_temp.invoke(prompt).content.strip()\n",
        "    print(f\"Round {rnd+1} | response:\", output_res)\n",
        "  except Exception as e:\n",
        "    print(f\"Round {rnd+1} | Error:\", e)\n",
        "\n",
        "  print(\"--\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbra6aNZgtM3",
        "outputId": "3530e22f-80b1-4a48-acf1-ccebd2b5ebd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1 | response: **Your bank, in your pocket.**\n",
            "------------------------------------------------------------\n",
            "Round 2 | response: Here's one slogan:\n",
            "\n",
            "**Your bank, in your hand.**\n",
            "------------------------------------------------------------\n",
            "Round 3 | response: Here are a few options, pick the one that best fits the app's specific focus:\n",
            "\n",
            "**Your Bank. In Your Pocket.**\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_high_temp\n",
        "prompt = \"Write one slogan for a mobile banking application.\"\n",
        "for rnd in range(3):\n",
        "  try:\n",
        "    output_res = llm_high_temp.invoke(prompt).content.strip()\n",
        "    print(f\"Round {rnd+1} | response:\", output_res)\n",
        "  except Exception as e:\n",
        "    print(f\"Round {rnd+1} | Error:\", e)\n",
        "\n",
        "  print(\"--\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAlpPN-nhd4w",
        "outputId": "769ece5b-0fb5-4f19-e7df-b9deeda92c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1 | response: **Your Bank. In Your Pocket.**\n",
            "------------------------------------------------------------\n",
            "Round 2 | response: Your bank, at your fingertips.\n",
            "------------------------------------------------------------\n",
            "Round 3 | response: **Financial freedom, at your fingertips.**\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "- Low temp → Reliable, consistent outputs. Useful for classification, extraction, or when you want reproducibility.\n",
        "- High temp → Diverse, creative slogans. Useful for brainstorming, ideation, or when multiple fresh options are desired."
      ],
      "metadata": {
        "id": "jp0VKZZVhzsD"
      }
    }
  ]
}